# RouteSim Mooncake Demo Configuration
# Tuned for Mooncake production trace characteristics:
# - Long-context requests from Kimi chatbot
# - High prefix sharing via block-level KV cache hashes
# - Block size = 16 tokens (matching vLLM default)
#
# Source: Mooncake (Qin et al., FAST 2025 Best Paper)
# https://github.com/kvcache-ai/Mooncake

[simulation]
name = "mooncake-prefix-overlap"
seed = 42
warmup_requests = 50

[cluster]
gpu_type = "H100Sxm"
num_backends = 8
max_batch_tokens = 65536
max_queue_depth = 256
kv_cache_blocks = 32768
kv_block_size = 16

[cluster.compute_model]
prefill_tokens_per_sec = 50000
decode_tokens_per_sec_batch1 = 80
decode_throughput_saturation_batch = 64
decode_tokens_per_sec_saturated = 3200

[trace]
format = "mooncake"
path = "traces/mooncake_sample.jsonl"
