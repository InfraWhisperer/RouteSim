# RouteSim Multi-Model Configuration
# Different LoRA adapters on different backends

[simulation]
name = "multi-model"
seed = 42
warmup_requests = 50

[cluster]
gpu_type = "A100Sxm80"
num_backends = 6
max_batch_tokens = 8192
max_queue_depth = 128
kv_cache_blocks = 16384
kv_block_size = 16

[cluster.compute_model]
prefill_tokens_per_sec = 35000
decode_tokens_per_sec_batch1 = 60
decode_throughput_saturation_batch = 48
decode_tokens_per_sec_saturated = 2400

[trace]
format = "compact_jsonl"
path = "traces/example_trace.jsonl"
